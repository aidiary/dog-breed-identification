{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../data/train'\n",
    "valid_dir = '../data/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(imgpath, size):\n",
    "    img = image.load_img(imgpath, target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "train_paths = glob.glob(os.path.join(train_dir, '*', '*.jpg'))\n",
    "valid_paths = glob.glob(os.path.join(valid_dir, '*', '*.jpg'))\n",
    "random.shuffle(train_paths)\n",
    "random.shuffle(valid_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/train/newfoundland/cf3697f8f3ee67b50cedaa63904ab5e8.jpg',\n",
       " '../data/train/cocker_spaniel/37e42e634970f00ab6f6ca7db8239606.jpg',\n",
       " '../data/train/bluetick/b66b6ff2ff16c6e746af3ef624e471f1.jpg',\n",
       " '../data/train/curly-coated_retriever/3ad193d212c34fb9e5c77a1dfc99efe1.jpg',\n",
       " '../data/train/beagle/86f0e4abee677119258764eadc368b9d.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/valid/clumber/54ece8d1cb7a77b9968d714fba342c36.jpg',\n",
       " '../data/valid/miniature_schnauzer/692965e541833d6cf6089b0d416f0c0f.jpg',\n",
       " '../data/valid/affenpinscher/c32fb0c78bfc35f176ae7090155ef2c9.jpg',\n",
       " '../data/valid/gordon_setter/18de05937a44cb467b229889f8a95bcb.jpg',\n",
       " '../data/valid/lhasa/fc7317da160bff89cd13aacc980adf26.jpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9199, 1023)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_paths), len(valid_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract VGG16 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_images = np.zeros((len(train_paths), 224, 224, 3), dtype='float32')\n",
    "for i, imgpath in enumerate(train_paths):\n",
    "    img = read_img(imgpath, (224, 224))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    train_images[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9199, 224, 224, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images = np.zeros((len(valid_paths), 224, 224, 3), dtype='float32')\n",
    "for i, imgpath in enumerate(valid_paths):\n",
    "    img = read_img(imgpath, (224, 224))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    valid_images[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 224, 224, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "vgg_bottleneck.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 512/9199 [>.............................] - ETA: 5:34"
     ]
    }
   ],
   "source": [
    "train_feats = vgg_bottleneck.predict(train_images, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_feats = vgg_bottleneck.predict(valid_images, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9199, 512)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_feats_vgg16.npy', train_feats)\n",
    "np.save('valid_feats_vgg16.npy', valid_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = list(set([x.split('/')[3] for x in train_paths]))\n",
    "dogs = sorted(dogs)\n",
    "len(dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78, 32, 15, 34, 9, 48, 63, 110, 56, 6]\n",
      "[31, 77, 0, 50, 70, 84, 106, 61, 54, 20]\n",
      "(1023, 120)\n"
     ]
    }
   ],
   "source": [
    "train_labels = [dogs.index(x) for x in [x.split('/')[3] for x in train_paths]]\n",
    "print(train_labels[:10])\n",
    "\n",
    "valid_labels = [dogs.index(x) for x in [x.split('/')[3] for x in valid_paths]]\n",
    "print(valid_labels[:10])\n",
    "\n",
    "from keras.utils import np_utils\n",
    "valid_onehot= np_utils.to_categorical(valid_labels)\n",
    "print(valid_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg on VGG bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=1234, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', random_state=1234)\n",
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(train_feats)\n",
    "train_feats_norm = scaler.transform(train_feats)\n",
    "valid_feats_norm = scaler.transform(valid_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koichiro.mori/miniconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=1234, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(train_feats_norm, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 120)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_probs = logreg.predict_proba(valid_feats_norm)\n",
    "valid_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023,)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds = logreg.predict(valid_feats_norm)\n",
    "valid_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31,   1, 119,  50, 103,  84,  77,  61,  54,  64])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds[:10]  # 予測したラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 77, 0, 50, 70, 84, 106, 61, 54, 20]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_labels[:10]  # 正解ラベル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation VGG LogLoss 1.4694004211113254\n"
     ]
    }
   ],
   "source": [
    "print('Validation VGG LogLoss {}'.format(log_loss(valid_onehot, valid_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation VGG Accuracy 0.6490713587487781\n"
     ]
    }
   ],
   "source": [
    "print('Validation VGG Accuracy {}'.format(accuracy_score(valid_labels, valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/test/unknown/92e1474b1351dc69071cea6b792fd499.jpg',\n",
       " '../data/test/unknown/c8e6cb302052b1a985c2d9dc934e757d.jpg',\n",
       " '../data/test/unknown/a08b6c26e51a3ee261222985d1641072.jpg',\n",
       " '../data/test/unknown/d20a3f640bc733ec21e4670d1a7c29f7.jpg',\n",
       " '../data/test/unknown/02ce818b70734ce460d0ffc47e6b9682.jpg']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = '../data/test'\n",
    "test_paths = glob.glob(os.path.join(test_dir, 'unknown', '*.jpg'))\n",
    "test_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_images = np.zeros((len(test_paths), 224, 224, 3), dtype='float32')\n",
    "for i, imgpath in enumerate(test_paths):\n",
    "    img = read_img(imgpath, (224, 224))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    test_images[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10357/10357 [==============================] - 410s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "test_feats = vgg_bottleneck.predict(test_images, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 512)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_feats_vgg16.npy', train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats_norm = scaler.transform(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 120)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs = logreg.predict_proba(test_feats_norm)\n",
    "test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = test_probs.T  # (120, 10357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission csv\n",
    "import pandas as pd\n",
    "\n",
    "data = {}\n",
    "data['id'] = [x.split('/')[4].replace('.jpg', '') for x in test_paths]\n",
    "for i, dog in enumerate(dogs):\n",
    "    data[dog] = test_probs[i]\n",
    "\n",
    "submissions = pd.DataFrame(\n",
    "    data=data,\n",
    "    columns=['id'] + dogs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92e1474b1351dc69071cea6b792fd499</td>\n",
       "      <td>6.606660e-08</td>\n",
       "      <td>6.193216e-03</td>\n",
       "      <td>9.409237e-07</td>\n",
       "      <td>1.531382e-06</td>\n",
       "      <td>8.139623e-07</td>\n",
       "      <td>1.273572e-07</td>\n",
       "      <td>1.675252e-07</td>\n",
       "      <td>9.892289e-08</td>\n",
       "      <td>1.419992e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.138502e-10</td>\n",
       "      <td>6.004503e-08</td>\n",
       "      <td>2.579528e-07</td>\n",
       "      <td>1.923375e-04</td>\n",
       "      <td>4.861497e-05</td>\n",
       "      <td>3.182413e-04</td>\n",
       "      <td>4.346007e-07</td>\n",
       "      <td>1.294497e-03</td>\n",
       "      <td>1.725496e-04</td>\n",
       "      <td>2.032557e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c8e6cb302052b1a985c2d9dc934e757d</td>\n",
       "      <td>4.953636e-07</td>\n",
       "      <td>3.066073e-06</td>\n",
       "      <td>1.636236e-06</td>\n",
       "      <td>1.528126e-07</td>\n",
       "      <td>5.940144e-09</td>\n",
       "      <td>2.430919e-09</td>\n",
       "      <td>2.674669e-05</td>\n",
       "      <td>4.960597e-05</td>\n",
       "      <td>8.401744e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>6.215988e-04</td>\n",
       "      <td>2.947099e-07</td>\n",
       "      <td>7.660395e-07</td>\n",
       "      <td>7.687343e-07</td>\n",
       "      <td>6.747192e-09</td>\n",
       "      <td>8.631270e-07</td>\n",
       "      <td>1.197412e-09</td>\n",
       "      <td>1.398904e-06</td>\n",
       "      <td>1.421352e-08</td>\n",
       "      <td>2.657780e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a08b6c26e51a3ee261222985d1641072</td>\n",
       "      <td>4.299817e-06</td>\n",
       "      <td>3.842691e-05</td>\n",
       "      <td>1.336552e-05</td>\n",
       "      <td>8.165357e-07</td>\n",
       "      <td>6.299205e-07</td>\n",
       "      <td>1.639637e-06</td>\n",
       "      <td>4.407677e-07</td>\n",
       "      <td>1.572657e-06</td>\n",
       "      <td>2.909368e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.361840e-06</td>\n",
       "      <td>2.312744e-05</td>\n",
       "      <td>1.688559e-05</td>\n",
       "      <td>2.496015e-04</td>\n",
       "      <td>4.251381e-05</td>\n",
       "      <td>1.396039e-06</td>\n",
       "      <td>1.938594e-06</td>\n",
       "      <td>9.430178e-06</td>\n",
       "      <td>5.628175e-04</td>\n",
       "      <td>7.462807e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d20a3f640bc733ec21e4670d1a7c29f7</td>\n",
       "      <td>5.472645e-10</td>\n",
       "      <td>2.567184e-08</td>\n",
       "      <td>4.765130e-07</td>\n",
       "      <td>1.348157e-13</td>\n",
       "      <td>3.258201e-09</td>\n",
       "      <td>2.402619e-08</td>\n",
       "      <td>2.989557e-13</td>\n",
       "      <td>1.165050e-11</td>\n",
       "      <td>1.389454e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.989962e-11</td>\n",
       "      <td>7.986040e-10</td>\n",
       "      <td>2.387630e-12</td>\n",
       "      <td>1.388281e-09</td>\n",
       "      <td>8.699295e-07</td>\n",
       "      <td>2.909222e-09</td>\n",
       "      <td>3.056509e-09</td>\n",
       "      <td>5.180248e-08</td>\n",
       "      <td>2.898896e-09</td>\n",
       "      <td>2.594655e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02ce818b70734ce460d0ffc47e6b9682</td>\n",
       "      <td>1.470398e-06</td>\n",
       "      <td>4.573357e-04</td>\n",
       "      <td>1.391983e-04</td>\n",
       "      <td>1.021771e-06</td>\n",
       "      <td>1.003380e-05</td>\n",
       "      <td>8.066151e-09</td>\n",
       "      <td>3.517993e-08</td>\n",
       "      <td>1.578568e-06</td>\n",
       "      <td>1.310436e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.253715e-06</td>\n",
       "      <td>5.214195e-06</td>\n",
       "      <td>6.812498e-06</td>\n",
       "      <td>1.762883e-05</td>\n",
       "      <td>7.953946e-06</td>\n",
       "      <td>1.695986e-07</td>\n",
       "      <td>7.607798e-08</td>\n",
       "      <td>3.163661e-04</td>\n",
       "      <td>1.206462e-07</td>\n",
       "      <td>2.385954e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>d08c477d0d6b6060163c61f030699bb3</td>\n",
       "      <td>4.584595e-08</td>\n",
       "      <td>1.496215e-04</td>\n",
       "      <td>2.501201e-07</td>\n",
       "      <td>3.168227e-06</td>\n",
       "      <td>8.652122e-06</td>\n",
       "      <td>2.776078e-05</td>\n",
       "      <td>2.052213e-02</td>\n",
       "      <td>7.277240e-03</td>\n",
       "      <td>2.091364e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.550815e-02</td>\n",
       "      <td>3.208853e-03</td>\n",
       "      <td>5.249872e-06</td>\n",
       "      <td>1.272376e-01</td>\n",
       "      <td>2.071573e-05</td>\n",
       "      <td>6.198020e-03</td>\n",
       "      <td>1.251202e-06</td>\n",
       "      <td>1.224297e-04</td>\n",
       "      <td>6.092362e-07</td>\n",
       "      <td>2.855371e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>a8b462c178d69221ee633d425785133c</td>\n",
       "      <td>1.436987e-05</td>\n",
       "      <td>1.010737e-09</td>\n",
       "      <td>4.701095e-07</td>\n",
       "      <td>1.638541e-08</td>\n",
       "      <td>2.745391e-07</td>\n",
       "      <td>2.241749e-05</td>\n",
       "      <td>8.305233e-07</td>\n",
       "      <td>1.227100e-04</td>\n",
       "      <td>1.174185e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.495316e-05</td>\n",
       "      <td>4.230937e-05</td>\n",
       "      <td>5.603171e-08</td>\n",
       "      <td>7.009358e-09</td>\n",
       "      <td>7.861452e-09</td>\n",
       "      <td>2.014514e-09</td>\n",
       "      <td>4.227806e-06</td>\n",
       "      <td>1.083687e-07</td>\n",
       "      <td>4.291380e-08</td>\n",
       "      <td>2.143064e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354</th>\n",
       "      <td>8913db55e9966d331e7759f748e2abef</td>\n",
       "      <td>1.538961e-03</td>\n",
       "      <td>4.681865e-07</td>\n",
       "      <td>4.958053e-05</td>\n",
       "      <td>2.931596e-04</td>\n",
       "      <td>1.616257e-04</td>\n",
       "      <td>5.336579e-07</td>\n",
       "      <td>4.022614e-07</td>\n",
       "      <td>6.014989e-06</td>\n",
       "      <td>3.937980e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.113286e-07</td>\n",
       "      <td>3.334933e-08</td>\n",
       "      <td>6.462503e-06</td>\n",
       "      <td>2.931564e-06</td>\n",
       "      <td>3.206040e-05</td>\n",
       "      <td>4.989489e-06</td>\n",
       "      <td>4.336434e-07</td>\n",
       "      <td>1.291783e-07</td>\n",
       "      <td>2.659614e-06</td>\n",
       "      <td>1.695278e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>2bf6d0177046ba8936973513f3eafce0</td>\n",
       "      <td>3.897708e-06</td>\n",
       "      <td>1.107374e-10</td>\n",
       "      <td>7.295774e-10</td>\n",
       "      <td>3.876619e-10</td>\n",
       "      <td>1.444610e-07</td>\n",
       "      <td>1.769690e-11</td>\n",
       "      <td>1.202277e-07</td>\n",
       "      <td>3.099302e-08</td>\n",
       "      <td>1.361867e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.513208e-09</td>\n",
       "      <td>6.974926e-09</td>\n",
       "      <td>3.917347e-10</td>\n",
       "      <td>6.394393e-11</td>\n",
       "      <td>7.732171e-11</td>\n",
       "      <td>8.278305e-12</td>\n",
       "      <td>5.187356e-08</td>\n",
       "      <td>1.816232e-09</td>\n",
       "      <td>1.028645e-07</td>\n",
       "      <td>4.594130e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>27c5d715e02f0c7d7758cd81abba9018</td>\n",
       "      <td>1.334799e-06</td>\n",
       "      <td>4.871052e-05</td>\n",
       "      <td>3.166450e-06</td>\n",
       "      <td>1.420197e-04</td>\n",
       "      <td>1.285181e-02</td>\n",
       "      <td>3.711823e-07</td>\n",
       "      <td>4.440370e-05</td>\n",
       "      <td>3.409883e-04</td>\n",
       "      <td>1.175569e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.526798e-06</td>\n",
       "      <td>2.206475e-03</td>\n",
       "      <td>8.346893e-06</td>\n",
       "      <td>2.837560e-02</td>\n",
       "      <td>7.995367e-07</td>\n",
       "      <td>7.402419e-01</td>\n",
       "      <td>2.765579e-04</td>\n",
       "      <td>6.705142e-04</td>\n",
       "      <td>1.333349e-04</td>\n",
       "      <td>3.868890e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10357 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  affenpinscher  afghan_hound  \\\n",
       "0      92e1474b1351dc69071cea6b792fd499   6.606660e-08  6.193216e-03   \n",
       "1      c8e6cb302052b1a985c2d9dc934e757d   4.953636e-07  3.066073e-06   \n",
       "2      a08b6c26e51a3ee261222985d1641072   4.299817e-06  3.842691e-05   \n",
       "3      d20a3f640bc733ec21e4670d1a7c29f7   5.472645e-10  2.567184e-08   \n",
       "4      02ce818b70734ce460d0ffc47e6b9682   1.470398e-06  4.573357e-04   \n",
       "...                                 ...            ...           ...   \n",
       "10352  d08c477d0d6b6060163c61f030699bb3   4.584595e-08  1.496215e-04   \n",
       "10353  a8b462c178d69221ee633d425785133c   1.436987e-05  1.010737e-09   \n",
       "10354  8913db55e9966d331e7759f748e2abef   1.538961e-03  4.681865e-07   \n",
       "10355  2bf6d0177046ba8936973513f3eafce0   3.897708e-06  1.107374e-10   \n",
       "10356  27c5d715e02f0c7d7758cd81abba9018   1.334799e-06  4.871052e-05   \n",
       "\n",
       "       african_hunting_dog      airedale  american_staffordshire_terrier  \\\n",
       "0             9.409237e-07  1.531382e-06                    8.139623e-07   \n",
       "1             1.636236e-06  1.528126e-07                    5.940144e-09   \n",
       "2             1.336552e-05  8.165357e-07                    6.299205e-07   \n",
       "3             4.765130e-07  1.348157e-13                    3.258201e-09   \n",
       "4             1.391983e-04  1.021771e-06                    1.003380e-05   \n",
       "...                    ...           ...                             ...   \n",
       "10352         2.501201e-07  3.168227e-06                    8.652122e-06   \n",
       "10353         4.701095e-07  1.638541e-08                    2.745391e-07   \n",
       "10354         4.958053e-05  2.931596e-04                    1.616257e-04   \n",
       "10355         7.295774e-10  3.876619e-10                    1.444610e-07   \n",
       "10356         3.166450e-06  1.420197e-04                    1.285181e-02   \n",
       "\n",
       "        appenzeller  australian_terrier       basenji        basset  ...  \\\n",
       "0      1.273572e-07        1.675252e-07  9.892289e-08  1.419992e-04  ...   \n",
       "1      2.430919e-09        2.674669e-05  4.960597e-05  8.401744e-07  ...   \n",
       "2      1.639637e-06        4.407677e-07  1.572657e-06  2.909368e-06  ...   \n",
       "3      2.402619e-08        2.989557e-13  1.165050e-11  1.389454e-09  ...   \n",
       "4      8.066151e-09        3.517993e-08  1.578568e-06  1.310436e-02  ...   \n",
       "...             ...                 ...           ...           ...  ...   \n",
       "10352  2.776078e-05        2.052213e-02  7.277240e-03  2.091364e-01  ...   \n",
       "10353  2.241749e-05        8.305233e-07  1.227100e-04  1.174185e-08  ...   \n",
       "10354  5.336579e-07        4.022614e-07  6.014989e-06  3.937980e-03  ...   \n",
       "10355  1.769690e-11        1.202277e-07  3.099302e-08  1.361867e-10  ...   \n",
       "10356  3.711823e-07        4.440370e-05  3.409883e-04  1.175569e-03  ...   \n",
       "\n",
       "         toy_poodle   toy_terrier        vizsla  walker_hound    weimaraner  \\\n",
       "0      3.138502e-10  6.004503e-08  2.579528e-07  1.923375e-04  4.861497e-05   \n",
       "1      6.215988e-04  2.947099e-07  7.660395e-07  7.687343e-07  6.747192e-09   \n",
       "2      2.361840e-06  2.312744e-05  1.688559e-05  2.496015e-04  4.251381e-05   \n",
       "3      2.989962e-11  7.986040e-10  2.387630e-12  1.388281e-09  8.699295e-07   \n",
       "4      1.253715e-06  5.214195e-06  6.812498e-06  1.762883e-05  7.953946e-06   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "10352  2.550815e-02  3.208853e-03  5.249872e-06  1.272376e-01  2.071573e-05   \n",
       "10353  3.495316e-05  4.230937e-05  5.603171e-08  7.009358e-09  7.861452e-09   \n",
       "10354  6.113286e-07  3.334933e-08  6.462503e-06  2.931564e-06  3.206040e-05   \n",
       "10355  1.513208e-09  6.974926e-09  3.917347e-10  6.394393e-11  7.732171e-11   \n",
       "10356  2.526798e-06  2.206475e-03  8.346893e-06  2.837560e-02  7.995367e-07   \n",
       "\n",
       "       welsh_springer_spaniel  west_highland_white_terrier       whippet  \\\n",
       "0                3.182413e-04                 4.346007e-07  1.294497e-03   \n",
       "1                8.631270e-07                 1.197412e-09  1.398904e-06   \n",
       "2                1.396039e-06                 1.938594e-06  9.430178e-06   \n",
       "3                2.909222e-09                 3.056509e-09  5.180248e-08   \n",
       "4                1.695986e-07                 7.607798e-08  3.163661e-04   \n",
       "...                       ...                          ...           ...   \n",
       "10352            6.198020e-03                 1.251202e-06  1.224297e-04   \n",
       "10353            2.014514e-09                 4.227806e-06  1.083687e-07   \n",
       "10354            4.989489e-06                 4.336434e-07  1.291783e-07   \n",
       "10355            8.278305e-12                 5.187356e-08  1.816232e-09   \n",
       "10356            7.402419e-01                 2.765579e-04  6.705142e-04   \n",
       "\n",
       "       wire-haired_fox_terrier  yorkshire_terrier  \n",
       "0                 1.725496e-04       2.032557e-07  \n",
       "1                 1.421352e-08       2.657780e-07  \n",
       "2                 5.628175e-04       7.462807e-08  \n",
       "3                 2.898896e-09       2.594655e-11  \n",
       "4                 1.206462e-07       2.385954e-06  \n",
       "...                        ...                ...  \n",
       "10352             6.092362e-07       2.855371e-06  \n",
       "10353             4.291380e-08       2.143064e-06  \n",
       "10354             2.659614e-06       1.695278e-05  \n",
       "10355             1.028645e-07       4.594130e-10  \n",
       "10356             1.333349e-04       3.868890e-05  \n",
       "\n",
       "[10357 rows x 121 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../submits', exist_ok=True)\n",
    "submissions.to_csv('../submits/logreg_vgg16_bottleneck.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
